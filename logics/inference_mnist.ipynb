{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "304e97f5-19a0-4e00-8e83-eb02e435195d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2467032/2266772600.py:55: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_model.load_state_dict(torch.load(\"mnist_autoencoder.pth\", map_location=device))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: (x > 0.5).float()),\n",
    "])\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "class CNNAutoencoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Un autoencodeur convolutionnel simple:\n",
    "         - Encoder: 2 blocs Conv -> MaxPool\n",
    "         - Decoder: 2 blocs ConvTranspose\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(CNNAutoencoder, self).__init__()\n",
    "        \n",
    "        # --- Encoder ---\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # Sortie: (B,32,14,14)\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)  # Sortie: (B,64,7,7)\n",
    "        )\n",
    "        \n",
    "        # --- Decoder ---\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2),  # (B,32,14,14)\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 1, kernel_size=2, stride=2)    # (B,1,28,28)\n",
    "            # Pas de sigmoid ici; on utilisera BCEWithLogitsLoss\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Création d'un modèle vide\n",
    "loaded_model = CNNAutoencoder().to(device)\n",
    "\n",
    "# Chargement des poids sauvegardés\n",
    "loaded_model.load_state_dict(torch.load(\"mnist_autoencoder.pth\", map_location=device))\n",
    "\n",
    "# Passage du modèle en mode évaluation\n",
    "loaded_model.eval()\n",
    "def random_drop_784(batch_images_flat, drop_probability):\n",
    "    \"\"\"\n",
    "    Supprime aléatoirement un pourcentage de bits (0 ou 1) dans chaque image et remplacer par -1.\n",
    "    \"\"\"\n",
    "    mask = (torch.rand_like(batch_images_flat) > drop_probability)\n",
    "    dropped_flat = batch_images_flat.clone()\n",
    "    dropped_flat[mask == 0] = -1  # on remplace les bits manquants et non reçus par -1.\n",
    "    return dropped_flat\n",
    "    \n",
    "def test_reconstruction(model, image_tensor, drop_probability=0.3):\n",
    "    \"\"\"\n",
    "    Reçoit une seule image (1,1,28,28),\n",
    "    remplace certains pixels par -1 (drop),\n",
    "    la passe à travers le modèle et retourne l'image reconstruite.\n",
    "    \"\"\"\n",
    "    model.eval()  # Mode évaluation\n",
    "    \n",
    "    # 1) Aplatissement\n",
    "    flat = image_tensor.view(1, -1)  # (1,784)\n",
    "    \n",
    "    # 2) Application du drop\n",
    "    dropped_flat = random_drop_784(flat, drop_probability)\n",
    "    \n",
    "    # 3) Reformatage en (1,1,28,28)\n",
    "    dropped_reshaped = dropped_flat.view(1, 1, 28, 28)\n",
    "    \n",
    "    # 4) Passage à travers le modèle (avec torch.no_grad pour éviter le calcul des gradients)\n",
    "    with torch.no_grad():\n",
    "        logits = model(dropped_reshaped)\n",
    "        reconstructed = torch.sigmoid(logits)  # Car BCEWithLogitsLoss a été utilisé\n",
    "    \n",
    "    return dropped_reshaped, reconstructed\n",
    "\n",
    "def save_reconstruction(original, dropped, reconstructed, prefix=\"output\"):\n",
    "    \"\"\"\n",
    "    Enregistre chaque les images.\n",
    "    \"\"\"\n",
    "    # Conversion des tenseurs en numpy pour l'affichage\n",
    "    original_np = original.cpu().numpy().squeeze()     # Format 28×28\n",
    "    dropped_np = dropped.cpu().numpy().squeeze()       # Format 28×28\n",
    "    reconstructed_np = reconstructed.cpu().numpy().squeeze()  # Format 28×28\n",
    "\n",
    "    # Enregistrement de l'image originale\n",
    "    plt.figure()\n",
    "    plt.imshow(original_np, cmap='gray', vmin=-1, vmax=1)\n",
    "    plt.title(\"Original\")\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f\"{prefix}_original.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Enregistrement de l'image modifiée (Dropped)\n",
    "    plt.figure()\n",
    "    plt.imshow(dropped_np, cmap='gray', vmin=-1, vmax=1)\n",
    "    plt.title(\"Dropped\")\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f\"{prefix}_dropped.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Enregistrement de l'image reconstruite\n",
    "    plt.figure()\n",
    "    plt.imshow(reconstructed_np, cmap='gray', vmin=-1, vmax=1)\n",
    "    plt.title(\"Reconstructed\")\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f\"{prefix}_reconstructed.png\")\n",
    "    plt.close()\n",
    "\n",
    "    print(\"Images saved as:\")\n",
    "    print(f\"{prefix}_original.png, {prefix}_dropped.png, {prefix}_reconstructed.png\")\n",
    "\n",
    "# Récupération d'un batch depuis le test_loader\n",
    "test_iter = iter(test_loader)\n",
    "test_images, _ = next(test_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9539baa-8dd2-49f4-9b2c-4b606bbd0a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images saved as:\n",
      "example_output.png_original.png, example_output.png_dropped.png, example_output.png_reconstructed.png\n"
     ]
    }
   ],
   "source": [
    "# Sélection de l'image (1,1,28,28)\n",
    "single_image = test_images[0].unsqueeze(0).to(device)\n",
    "\n",
    "# Appel de la fonction de test :\n",
    "dropped_img, reconstructed_img = test_reconstruction(\n",
    "    loaded_model, \n",
    "    single_image, \n",
    "    drop_probability=0.7\n",
    ")\n",
    "\n",
    "\n",
    "save_reconstruction(single_image, dropped_img, reconstructed_img, \"example_output.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe106e8e-18e6-4fba-9e73-430727f4b3ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2",
   "language": "python",
   "name": "tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
